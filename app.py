import streamlit as st
import pandas as pd
import folium
from folium.plugins import TimestampedGeoJson, Fullscreen, BeautifyIcon
from datetime import datetime, date
from streamlit.components.v1 import html

# ===========================
# åŸºæœ¬ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ===========================

def clean_str(s):
    return str(s).replace("\u3000", "").strip()

def detect_condition(row):
    def is_on(x):
        if pd.isna(x): return False
        s = str(x)
        return (s != "") and (s != "éè©²å½“") and (s != "0")

    if is_on(row.get("incident_condition_heatstroke")):
        return "ç†±ä¸­ç—‡"
    if is_on(row.get("incident_condition_flu")):
        return "ã‚¤ãƒ³ãƒ•ãƒ«"
    if is_on(row.get("incident_condition_snow")):
        return "é›ª"
    if is_on(row.get("incident_condition_covid19_suspect")):
        return "ã‚³ãƒ­ãƒŠç–‘ã„"
    return "ãã®ä»–/ãªã—"

def classify_available(info):
    if pd.isna(info): return None
    s = str(info).strip()
    if s == "åå®¹å¯": return True
    NG_WORDS = ["å‡¦ç½®å›°é›£", "å¿œç­”ãªã—", "æ‚£è€…å¯¾å¿œä¸­", "æº€åºŠ"]
    if any(w in s for w in NG_WORDS): return False
    return False

def read_any(file_obj):
    name = file_obj.name.lower()
    if name.endswith(".xlsx") or name.endswith(".xls"):
        return pd.read_excel(file_obj)
    return pd.read_csv(file_obj)

# ===========================
# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆé‡ã„ã®ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
# ===========================

def build_lines(emg, addr, scene):
    emg["case_id"] = emg["case_id"].astype(str).str.strip()
    scene["case_id"] = scene["case_id"].astype(str).str.strip()

    emg["related_hospital"] = emg["related_hospital"].astype(str).apply(clean_str)
    emg["hospital_name"] = emg["hospital_name"].astype(str).apply(clean_str)
    addr["hospital_name"] = addr["hospital_name"].astype(str).apply(clean_str)

    emg["inquiry_end_time"] = pd.to_datetime(emg["inquiry_end_time"], errors="coerce")
    emg["call_time"] = pd.to_datetime(emg["call_time"], errors="coerce")

    emg["call_hour"] = emg["call_time"].dt.hour
    emg["time_band"] = pd.cut(
        emg["call_hour"],
        bins=[0, 6, 12, 18, 24],
        labels=["0-6", "6-12", "12-18", "18-24"],
        right=False,
        include_lowest=True,
    )

    emg["main_condition"] = emg.apply(detect_condition, axis=1)

    scene2 = scene.rename(columns={"fX": "scene_lon", "fY": "scene_lat"})
    scene2 = (
        scene2[["case_id", "scene_lat", "scene_lon"]]
        .dropna()
        .drop_duplicates("case_id")
    )

    addr2 = addr.rename(columns={"fX": "hosp_lon", "fY": "hosp_lat"})
    addr2 = addr2[["hospital_name", "hosp_lat", "hosp_lon"]]

    emg_q = emg[emg["related_hospital"].str.len() > 0].copy()

    rel_addr = addr2.rename(columns={
        "hospital_name": "related_hospital",
        "hosp_lat": "rel_lat",
        "hosp_lon": "rel_lon",
    })
    emg_rel = emg_q.merge(rel_addr, on="related_hospital", how="left")

    final_addr = addr2.rename(columns={
        "hospital_name": "hospital_name",
        "hosp_lat": "final_lat",
        "hosp_lon": "final_lon",
    })
    emg_both = emg_rel.merge(final_addr, on="hospital_name", how="left")

    lines = emg_both.merge(scene2, on="case_id", how="left")
    lines["is_available"] = lines["obstruction_info"].apply(classify_available)

    lines = lines[[
        "case_id",
        "related_hospital",
        "obstruction_info",
        "inquiry_end_time",
        "scene_lat", "scene_lon",
        "rel_lat", "rel_lon",
        "hospital_name",
        "final_lat", "final_lon",
        "is_available",
        "time_band",
        "main_condition",
    ]].copy()

    return lines


@st.cache_data
def build_lines_cached(emg, addr, scene):
    return build_lines(emg, addr, scene)


# ===========================
# ãƒãƒƒãƒ—ç”Ÿæˆï¼ˆæœ€é©åŒ–æ¸ˆï¼‰
# ===========================

def make_connection_map(day, highlight_top10=True):

    MAX_ROWS = 3000
    if len(day) > MAX_ROWS:
        day = day.sort_values("inquiry_end_time").iloc[-MAX_ROWS:].copy()

    day = day.dropna(subset=["scene_lat", "scene_lon", "rel_lat", "rel_lon"])

    center_lat = pd.concat([day["scene_lat"], day["rel_lat"]]).mean()
    center_lon = pd.concat([day["scene_lon"], day["rel_lon"]]).mean()

    m = folium.Map(location=[center_lat, center_lon], zoom_start=11)
    Fullscreen().add_to(m)

    # ---- ç¾å ´ï¼ˆèµ¤ / ã‚ªãƒ¬ãƒ³ã‚¸ï¼‰----
    scene_stats = (
        day.groupby(["case_id", "scene_lat", "scene_lon"])
        .agg(n_total=("case_id", "size"),
             n_ng=("is_available", lambda s: (s == False).sum()))
        .reset_index()
    )
    scene_stats["reject_rate"] = scene_stats["n_ng"] / scene_stats["n_total"]

    THR = 0.5
    fg_s = folium.FeatureGroup(name="ç¾å ´ï¼ˆèµ¤=æ‹’å¦å¤šï¼‰", show=True)

    for _, r in scene_stats.iterrows():
        color = "red" if r["reject_rate"] >= THR else "orange"
        folium.CircleMarker(
            [r["scene_lat"], r["scene_lon"]],
            radius=4,
            color=color,
            fill=True,
            fill_opacity=0.8,
            popup=f"{r['case_id']} / ä¸å¯ç‡:{r['reject_rate']:.2f}",
        ).add_to(fg_s)
    fg_s.add_to(m)

    # ---- ç·šï¼ˆå¯ / ä¸å¯ / æœ€çµ‚æ¬é€ï¼‰----
    fg_ok = folium.FeatureGroup(name="å—å…¥å¯ï¼ˆé’ï¼‰", show=True)
    fg_ng = folium.FeatureGroup(name="å—å…¥ä¸å¯ï¼ˆèµ¤ï¼‰", show=True)
    fg_fin = folium.FeatureGroup(name="ä¸å¯â†’æœ€çµ‚æ¬é€ï¼ˆç·‘ï¼‰", show=False)

    day_ok = day[day["is_available"] == True]
    day_ng = day[day["is_available"] == False]
    day_ng_f = day_ng.dropna(subset=["final_lat", "final_lon"])

    for _, r in day_ok.iterrows():
        folium.PolyLine(
            [[r["scene_lat"], r["scene_lon"]], [r["rel_lat"], r["rel_lon"]]],
            color="blue", weight=2, opacity=0.7
        ).add_to(fg_ok)

    for _, r in day_ng.iterrows():
        folium.PolyLine(
            [[r["scene_lat"], r["scene_lon"]], [r["rel_lat"], r["rel_lon"]]],
            color="red", weight=2, opacity=0.7
        ).add_to(fg_ng)

    for _, r in day_ng_f.iterrows():
        folium.PolyLine(
            [[r["scene_lat"], r["scene_lon"]], [r["final_lat"], r["final_lon"]]],
            color="green", weight=2, opacity=0.7
        ).add_to(fg_fin)

    fg_ok.add_to(m)
    fg_ng.add_to(m)
    fg_fin.add_to(m)

    # ---- ç—…é™¢ãƒ”ãƒ³ï¼ˆå°å‹ï¼‰----
    fg_h = folium.FeatureGroup(name="ç—…é™¢ãƒ”ãƒ³", show=True)

    hosp_stats = (
        day.dropna(subset=["rel_lat", "rel_lon"])
        .groupby("related_hospital")
        .agg(lat=("rel_lat", "first"),
             lon=("rel_lon", "first"),
             n_total=("case_id", "nunique"),
             n_ok=("is_available", lambda s: (s == True).sum()),
             n_ng=("is_available", lambda s: (s == False).sum()))
        .reset_index()
    )

    thr = hosp_stats["n_total"].quantile(0.9) if len(hosp_stats) else None

    for _, r in hosp_stats.iterrows():
        base = "blue" if r["n_ok"] > 0 else "red"
        marker_color = "darkblue" if (thr and r["n_total"] >= thr and base=="blue") else base

        icon = BeautifyIcon(icon="hospital-o", icon_shape="marker",
                            background_color=marker_color, border_color=marker_color,
                            text_color="white", icon_size=[18, 18])

        folium.Marker(
            [r["lat"], r["lon"]],
            icon=icon,
            popup=f"{r['related_hospital']} / {r['n_total']}ä»¶",
        ).add_to(fg_h)

    fg_h.add_to(m)

    folium.LayerControl(collapsed=False).add_to(m)
    return m

# ===========================
# ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
# ===========================

def make_hospital_timeline_map(df, step_minutes=10):

    MAX_POINTS = 1500
    if len(df) > MAX_POINTS:
        df = df.sort_values("inquiry_end_time").iloc[-MAX_POINTS:]

    center_lat = df["lat"].mean()
    center_lon = df["lon"].mean()

    m = folium.Map(location=[center_lat, center_lon], zoom_start=12)
    Fullscreen().add_to(m)

    feats = []
    for _, r in df.iterrows():
        color = "blue" if r["is_available"] else "red"
        feats.append({
            "type": "Feature",
            "geometry": {"type": "Point", "coordinates": [r["lon"], r["lat"]]},
            "properties": {
                "time": r["inquiry_end_time"].isoformat(),
                "style": {"color": color, "fillColor": color, "radius": 6},
            },
        })

    tg = TimestampedGeoJson(
        {"type": "FeatureCollection", "features": feats},
        period=f"PT{step_minutes}M",
        auto_play=False,
        loop=False,
        date_options="YYYY-MM-DD HH:mm",
    )
    tg.add_to(m)
    return m

def folium_to_streamlit(m, height=650):
    html(m._repr_html_(), height=height)

# ===========================
# Streamlit æ¼”å‡º
# ===========================

st.set_page_config(page_title="æ•‘æ€¥Ã—ç—…é™¢ å¯è¦–åŒ–", layout="wide")
st.title("ğŸš‘ æ•‘æ€¥Ã—ç—…é™¢ å—å…¥çŠ¶æ³ å¯è¦–åŒ–ã‚¢ãƒ—ãƒª")

st.sidebar.header("1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
emg_file = st.sidebar.file_uploader("emergency_data", ["csv", "xlsx"])
addr_file = st.sidebar.file_uploader("flu_with_address", ["csv", "xlsx"])
scene_file = st.sidebar.file_uploader("Book1_for_csis", ["csv", "xlsx"])

if not (emg_file and addr_file and scene_file):
    st.info("3ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

with st.spinner("å‰å‡¦ç†ä¸­â€¦"):
    emg = read_any(emg_file)
    addr = read_any(addr_file)
    scene = read_any(scene_file)
    lines = build_lines_cached(emg, addr, scene)

# ---- æ—¥ä»˜å‡¦ç†ï¼ˆå®Œå…¨ç‰ˆï¼‰----
lines["date"] = pd.to_datetime(lines["inquiry_end_time"], errors="coerce").dt.date
date_series = lines["date"].dropna()

if date_series.empty:
    st.error("æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

min_date, max_date = date_series.min(), date_series.max()

st.sidebar.header("2ï¸âƒ£ ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶")

date_range = st.sidebar.date_input(
    "æœŸé–“ï¼ˆé–‹å§‹ã€œçµ‚äº†ï¼‰", (min_date, max_date),
    min_value=min_date, max_value=max_date
)

if isinstance(date_range, (list, tuple)):
    start_date, end_date = date_range
else:
    start_date, end_date = min_date, date_range

if start_date > end_date:
    start_date, end_date = end_date, start_date

mask = (lines["date"] >= start_date) & (lines["date"] <= end_date)
day_base = lines[mask].copy()

# ---- ç—…é™¢é¸æŠï¼ˆä»¶æ•°é †ï¼‰----
hosp_counts = (
    day_base.dropna(subset=["related_hospital"])
    .groupby("related_hospital")["case_id"]
    .nunique()
    .reset_index(name="n_cases")
    .sort_values("n_cases", ascending=False)
)

labels = ["ï¼ˆå…¨ã¦ï¼‰"]
map_lab = {"ï¼ˆå…¨ã¦ï¼‰": None}

for _, r in hosp_counts.iterrows():
    lab = f"{r['related_hospital']}ï¼ˆ{int(r['n_cases'])}ä»¶ï¼‰"
    labels.append(lab)
    map_lab[lab] = r["related_hospital"]

hosp_sel = st.sidebar.selectbox("ç—…é™¢ï¼ˆä»¶æ•°é †ï¼‰", labels)
hosp_name = map_lab[hosp_sel]

# ---- æ™‚é–“å¸¯ / ç—‡çŠ¶ ----
time_opt = ["ï¼ˆå…¨ã¦ï¼‰"] + ["0-6", "6-12", "12-18", "18-24"]
time_sel = st.sidebar.selectbox("æ™‚é–“å¸¯", time_opt)
time_val = None if time_sel == "ï¼ˆå…¨ã¦ï¼‰" else time_sel

cond_opt = ["ï¼ˆå…¨ã¦ï¼‰"] + sorted(day_base["main_condition"].dropna().unique())
cond_sel = st.sidebar.selectbox("ç—‡çŠ¶", cond_opt)
cond_val = None if cond_sel == "ï¼ˆå…¨ã¦ï¼‰" else cond_sel

# ---- ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ ----
day = day_base.copy()
if hosp_name:
    day = day[day["related_hospital"] == hosp_name]
if time_val:
    day = day[day["time_band"] == time_val]
if cond_val:
    day = day[day["main_condition"] == cond_val]

if day.empty:
    st.warning("è©²å½“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

st.write(f"### æœŸé–“: {start_date} ã€œ {end_date}ï¼ˆ{len(day)} ä»¶ï¼‰")

# ---- ãƒãƒƒãƒ—é¸æŠ ----
map_type = st.sidebar.radio("è¡¨ç¤ºãƒãƒƒãƒ—", ["ç¾å ´â†”ç—…é™¢ æ¥ç¶šãƒãƒƒãƒ—", "ç—…é™¢ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³"])

if map_type == "ç¾å ´â†”ç—…é™¢ æ¥ç¶šãƒãƒƒãƒ—":
    st.subheader("ğŸ—º ç¾å ´â†”ç—…é™¢ æ¥ç¶šãƒãƒƒãƒ—")
    m = make_connection_map(day)
    folium_to_streamlit(m)
else:
    st.subheader("â± ç—…é™¢ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³")

    if (end_date - start_date).days > 3:
        st.warning("ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³è¡¨ç¤ºã¯3æ—¥ä»¥å†…ã«ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    df = (
        day.dropna(subset=["rel_lat", "rel_lon"])
        .rename(columns={"rel_lat": "lat", "rel_lon": "lon"})
        [["related_hospital", "obstruction_info", "inquiry_end_time",
          "lat", "lon", "is_available"]]
        .sort_values("inquiry_end_time")
    )

    step = st.sidebar.slider("åˆ»ã¿ï¼ˆåˆ†ï¼‰", 5, 60, 10, 5)

    m = make_hospital_timeline_map(df, step_minutes=step)
    folium_to_streamlit(m)
